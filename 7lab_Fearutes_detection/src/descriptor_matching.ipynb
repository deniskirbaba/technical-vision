{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "# Reading images\n",
    "img_path = \"../images/\"\n",
    "obj_img_name = \"obj_book.webp\"\n",
    "scene_img_name = \"books_scene.jpg\"\n",
    "obj_img = cv.imread(img_path + obj_img_name, cv.IMREAD_COLOR)\n",
    "scene_img = cv.imread(img_path + scene_img_name, cv.IMREAD_COLOR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect feature points and compute descriptors\n",
    "sift = cv.SIFT_create()\n",
    "brief = cv.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "\n",
    "obj_fp = sift.detect(obj_img, None)\n",
    "scene_fp = sift.detect(scene_img, None)\n",
    "\n",
    "obj_fp, obj_descr = brief.compute(obj_img, obj_fp)\n",
    "scene_fp, scene_descr = brief.compute(scene_img, scene_fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "# Displaying SIFT feature points in green color with scale and orientation\n",
    "obj_out = cv.drawKeypoints(obj_img, obj_fp, None, color = (0, 255, 0) , flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "scene_out = cv.drawKeypoints(scene_img, scene_fp, None, color = (0, 255, 0) , flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv.imwrite(img_path + obj_img_name.rpartition('.')[0] + \"_sift.jpg\", obj_out)\n",
    "cv.imwrite(img_path + scene_img_name.rpartition('.')[0] + \"_sift.jpg\", scene_out)\n",
    "cv.imshow(\"Object features\", obj_out)\n",
    "cv.imshow(\"Scene features\", scene_out)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# Creating brute force descriptor matcher\n",
    "matcher = cv.BFMatcher(crossCheck=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# Creating brute force descriptor matcher with Hamming distance\n",
    "matcher = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Creating FLANN 5 kd-trees descriptor matcher for SIFT descriptors\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "matcher = cv.FlannBasedMatcher(index_params, dict())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Creating FLANN LSH descriptor matcher for ORB descriptors\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, table_number = 6, key_size = 12, multi_probe_level = 1)\n",
    "matcher = cv.FlannBasedMatcher(index_params, dict())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# Finding single best match for two sets of descriptors\n",
    "matches = matcher.match(obj_descr, scene_descr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - an index of feature point in the first set\n",
      "3396 - an index of feature point in the second set\n",
      "0 - an index of image in the second set\n",
      "330.8247375488281 - the distance between two descriptors\n"
     ]
    }
   ],
   "source": [
    "# Each match is an instance of cv::DMatch class containing following data\n",
    "\n",
    "print(matches[0].queryIdx, \"- an index of feature point in the first set\")\n",
    "print(matches[0].trainIdx, \"- an index of feature point in the second set\")\n",
    "print(matches[0].imgIdx, \"- an index of image in the second set\")\n",
    "print(matches[0].distance, \"- the distance between two descriptors\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# Finding k-nearest best match for two sets of descriptors and filtering them\n",
    "# Find kNN matches with k = 2\n",
    "matches = matcher.knnMatch(obj_descr, scene_descr, k = 2)\n",
    "# Select good matches\n",
    "knn_ratio = 0.75\n",
    "good = []\n",
    "for m in matches:\n",
    "    if len(m) > 1:\n",
    "        if m[0].distance < knn_ratio * m[1].distance:\n",
    "            good.append(m[0])\n",
    "matches = good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# Displaying top 50 matches\n",
    "num_matches = 50\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "img_match = cv.drawMatches(obj_img, obj_fp, scene_img, scene_fp, matches[:num_matches], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(0, 255, 0))\n",
    "cv.imwrite(img_path + \"scene_obj_1.jpg\", img_match)\n",
    "cv.imshow(\"Matches\", img_match)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "# Executing RANSAC to calculate the transformation matrix\n",
    "MIN_MATCH_COUNT = 10\n",
    "if len(matches) < MIN_MATCH_COUNT:\n",
    "    print(\"Not enough matches.\")\n",
    "\n",
    "# Create arrays of point coordinates\n",
    "obj_pts = np.float32([obj_fp[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "scene_pts = np.float32([scene_fp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "# Run RANSAC method\n",
    "M, mask = cv.findHomography(obj_pts, scene_pts, cv.RANSAC, 5)\n",
    "mask = mask.ravel().tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "# Displaying the location of the first image on the second one\n",
    "# Image corners\n",
    "h, w = obj_img.shape[:2]\n",
    "obj_box = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "obj_to_scene_box =cv.perspectiveTransform(obj_box, M)\n",
    "# Draw a red box on the scene image\n",
    "img_res = cv.polylines(scene_img, [np.int32(obj_to_scene_box)], True, (255, 0, 0), 3, cv.LINE_AA)\n",
    "cv.imwrite(img_path + \"scene_obj_1_ransac_box.jpg\", img_res)\n",
    "cv.imshow(\"Search result\", img_res)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Displaying inlier matches\n",
    "img_trans = cv.drawMatches(obj_img, obj_fp, scene_img, scene_fp,matches, None, matchesMask=mask, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(0, 255, 0))\n",
    "cv.imwrite(img_path + \"scene_obj_1_inliers.jpg\", img_trans)\n",
    "cv.imshow(\"Transformation\", img_trans)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
