{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Reading images\n",
    "img_path = \"../images/\"\n",
    "img_1_name = \"out_2.jpg\"\n",
    "img_2_name = \"out_3.jpg\"\n",
    "img_3_name = \"out_4.jpg\"\n",
    "img_1 = cv.imread(img_path + img_1_name, cv.IMREAD_COLOR)\n",
    "img_2 = cv.imread(img_path + img_2_name, cv.IMREAD_COLOR)\n",
    "img_3 = cv.imread(img_path + img_3_name, cv.IMREAD_COLOR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# Detect feature points and compute descriptors\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "img_1_fp, img_1_des = sift.detectAndCompute(img_1, None)\n",
    "img_2_fp, img_2_des = sift.detectAndCompute(img_2, None)\n",
    "img_3_fp, img_3_des = sift.detectAndCompute(img_3, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying SIFT feature points with scale and orientation\n",
    "img_1_out = cv.drawKeypoints(img_1, img_1_fp, None, color = (255, 0, 0) , flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img_2_out = cv.drawKeypoints(img_2, img_2_fp, None, color = (255, 0, 0) , flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "img_3_out = cv.drawKeypoints(img_3, img_3_fp, None, color = (255, 0, 0) , flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "img_out = np.concatenate((img_1_out, img_2_out, img_3_out), axis=1)\n",
    "\n",
    "cv.imwrite(img_path + \"panorama_features.jpg\", img_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Creating brute force descriptor matcher\n",
    "matcher = cv.BFMatcher(crossCheck=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def find_best_matches(query_des, train_des, k, knn_ratio):\n",
    "    # Find kNN matches with k = 2\n",
    "    matches = matcher.knnMatch(query_des, train_des, k=k)\n",
    "    # Select good matches\n",
    "    good = []\n",
    "    for m in matches:\n",
    "        if len(m) > 1:\n",
    "            if m[0].distance < knn_ratio * m[1].distance:\n",
    "                good.append(m[0])\n",
    "    return good"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Finding k-nearest best match for 1-2 and 3-2 descriptors of images and filtering them\n",
    "matches_1_2 = find_best_matches(img_1_des, img_2_des, 2, 0.75)\n",
    "matches_3_2 = find_best_matches(img_3_des, img_2_des, 2, 0.75)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying top 50 matches\n",
    "num_matches = 50\n",
    "matches_1_2 = sorted(matches_1_2, key = lambda x:x.distance)\n",
    "matches_3_2 = sorted(matches_3_2, key = lambda x:x.distance)\n",
    "\n",
    "img_match_1_2 = cv.drawMatches(img_1, img_1_fp, img_2, img_2_fp, matches_1_2[:num_matches], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(255, 0, 0))\n",
    "img_match_3_2 = cv.drawMatches(img_3, img_3_fp, img_2, img_2_fp, matches_3_2[:num_matches], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(255, 0, 0))\n",
    "\n",
    "cv.imwrite(img_path + \"matches_1_2.jpg\", img_match_1_2)\n",
    "cv.imwrite(img_path + \"matches_3_2.jpg\", img_match_3_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Executing RANSAC to calculate the transformation matrix\n",
    "MIN_MATCH_COUNT = 10\n",
    "if len(matches_1_2) < MIN_MATCH_COUNT or len(matches_3_2) < MIN_MATCH_COUNT:\n",
    "    print(\"Not enough matches.\")\n",
    "\n",
    "# Create arrays of point coordinates\n",
    "img_1_pts = np.float32([img_1_fp[m.queryIdx].pt for m in matches_1_2]).reshape(-1, 1, 2)\n",
    "img_2_1_pts = np.float32([img_2_fp[m.trainIdx].pt for m in matches_1_2]).reshape(-1, 1, 2)\n",
    "\n",
    "img_3_pts = np.float32([img_3_fp[m.queryIdx].pt for m in matches_3_2]).reshape(-1, 1, 2)\n",
    "img_2_3_pts = np.float32([img_2_fp[m.trainIdx].pt for m in matches_3_2]).reshape(-1, 1, 2)\n",
    "\n",
    "# Run RANSAC method\n",
    "M_1_2, mask_1_2 = cv.findHomography(img_1_pts, img_2_1_pts, cv.RANSAC, 5)\n",
    "mask_1_2 = mask_1_2.ravel().tolist()\n",
    "\n",
    "M_3_2, mask_3_2 = cv.findHomography(img_3_pts, img_2_3_pts, cv.RANSAC, 5)\n",
    "mask_3_2 = mask_3_2.ravel().tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying inlier matches\n",
    "img_trans_1_2 = cv.drawMatches(img_1, img_1_fp, img_2, img_2_fp, matches_1_2, None, matchesMask=mask_1_2, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(0, 255, 0))\n",
    "img_trans_3_2 = cv.drawMatches(img_3, img_3_fp, img_2, img_2_fp, matches_3_2, None, matchesMask=mask_3_2, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, matchColor=(0, 255, 0))\n",
    "\n",
    "cv.imwrite(img_path + \"img_inliers_1_2.jpg\", img_trans_1_2)\n",
    "cv.imwrite(img_path + \"img_inliers_3_2.jpg\", img_trans_3_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Images corners\n",
    "h_1, w_1 = img_1.shape[:2]\n",
    "h_3, w_3 = img_3.shape[:2]\n",
    "img_1_box = np.float32([[0, 0], [0, h_1 - 1], [w_1 - 1, h_1 - 1], [w_1 - 1, 0]]).reshape(-1, 1, 2)\n",
    "img_3_box = np.float32([[0, 0], [0, h_3 - 1], [w_3 - 1, h_3 - 1], [w_3 - 1, 0]]).reshape(-1, 1, 2)\n",
    "img_1_to_img_2_box =cv.perspectiveTransform(img_1_box, M_1_2)\n",
    "img_3_to_img_2_box =cv.perspectiveTransform(img_3_box, M_3_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Compute paddings\n",
    "top_padding = int(max(-img_1_to_img_2_box[0][0, 1], -img_3_to_img_2_box[3][0, 1], 0))\n",
    "bot_padding = int(max(img_1_to_img_2_box[1][0, 1] - img_2.shape[0], img_3_to_img_2_box[2][0, 1] - img_2.shape[0], 0))\n",
    "left_padding = int(max(-img_1_to_img_2_box[0][0, 0], -img_1_to_img_2_box[1][0, 0], 0))\n",
    "right_padding = int(max(img_3_to_img_2_box[3][0, 0] - img_2.shape[1], img_3_to_img_2_box[2][0, 0] - img_2.shape[1], 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create panoramic image\n",
    "panoramic_img = cv.copyMakeBorder(img_2, top_padding, bot_padding, left_padding, right_padding, borderType=cv.BORDER_CONSTANT)\n",
    "cv.imwrite(img_path + \"panoramic_img.jpg\", panoramic_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Shift images boxes\n",
    "translation_matrix = np.array([[1, 0, left_padding], [0, 1, top_padding], [0, 0, 1]])\n",
    "img_1_to_img_2_box_shifted = cv.perspectiveTransform(img_1_to_img_2_box, translation_matrix)\n",
    "img_3_to_img_2_box_shifted = cv.perspectiveTransform(img_3_to_img_2_box, translation_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw boxes on panoramic image\n",
    "pano_with_boxes = np.copy(panoramic_img)\n",
    "pano_with_boxes = cv.polylines(pano_with_boxes, [np.int32(img_1_to_img_2_box_shifted)], True, (255, 0, 0), 3, cv.LINE_AA)\n",
    "pano_with_boxes = cv.polylines(pano_with_boxes, [np.int32(img_3_to_img_2_box_shifted)], True, (255, 0, 0), 3, cv.LINE_AA)\n",
    "cv.imwrite(img_path + \"pano_boxes.jpg\", pano_with_boxes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform warp for images 1 and 3\n",
    "img_1_warp =cv.warpPerspective(img_1, np.matmul(translation_matrix, M_1_2), dsize=(panoramic_img.shape[1], panoramic_img.shape[0]))\n",
    "img_3_warp =cv.warpPerspective(img_3, np.matmul(translation_matrix, M_3_2), dsize=(panoramic_img.shape[1], panoramic_img.shape[0]))\n",
    "cv.imwrite(img_path + \"img_1_warp.jpg\", img_1_warp)\n",
    "cv.imwrite(img_path + \"img_3_warp.jpg\", img_3_warp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create masks for images 1, 2, 3\n",
    "pan_h, pan_w = panoramic_img.shape[:2]\n",
    "\n",
    "img_1_mask = np.zeros((pan_h, pan_w), dtype=np.uint8)\n",
    "img_1_mask = cv.fillConvexPoly(img_1_mask, np.int32(img_1_to_img_2_box_shifted), 255)\n",
    "\n",
    "img_2_mask = np.zeros((pan_h, pan_w), dtype=np.uint8)\n",
    "img_2_mask[top_padding:(pan_h - bot_padding), left_padding:(pan_w - right_padding)] = 255\n",
    "\n",
    "img_3_mask = np.zeros((pan_h, pan_w), dtype=np.uint8)\n",
    "img_3_mask = cv.fillConvexPoly(img_3_mask, np.int32(img_3_to_img_2_box_shifted), 255)\n",
    "\n",
    "# Save masks\n",
    "cv.imwrite(img_path + \"img_1_mask.jpg\", img_1_mask)\n",
    "cv.imwrite(img_path + \"img_2_mask.jpg\", img_2_mask)\n",
    "cv.imwrite(img_path + \"img_3_mask.jpg\", img_3_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Marge all images into panoramic one\n",
    "\n",
    "img_1_3_mask = cv.bitwise_xor(img_1_mask, img_3_mask) - cv.bitwise_and(cv.bitwise_xor(img_1_mask, img_3_mask), img_2_mask)\n",
    "\n",
    "img_1_warp_cropped = cv.bitwise_and(img_1_warp, img_1_warp, mask=img_1_3_mask)\n",
    "img_3_warp_cropped = cv.bitwise_and(img_3_warp, img_3_warp, mask=img_1_3_mask)\n",
    "\n",
    "result = cv.add(cv.add(img_1_warp_cropped, img_3_warp_cropped), panoramic_img)\n",
    "\n",
    "cv.imwrite(img_path + \"result.jpg\", result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
